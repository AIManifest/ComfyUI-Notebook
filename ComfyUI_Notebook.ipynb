{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AIManifest/ComfyUI-Notebook/blob/master/ComfyUI_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<left><font color=\"orange\" size=\"16\"><b>ComfyUI-Notebook</b></font></left>"
      ],
      "metadata": {
        "id": "0SLoofuGZFd-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title $\\color{orange}{\\textsf{Setup HOME Path for Root Working Directory (Optional)}}$\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    gdrive = '/content/drive/'\n",
        "    drive.mount(gdrive)\n",
        "    HOME = '/content/'\n",
        "    print(f'Root Working Directory: {HOME}')\n",
        "except:\n",
        "    print(f'Colab not Detected, Changing Paths to Appropriate Root Directory (\"/workspace\") for Jupyter')\n",
        "    HOME = '/workspace/'\n",
        "    print(f'Root Working Directory: {HOME}')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ZjB-tNEA0_pK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0023d4fe-3376-4448-e918-f21f22bc393e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n",
            "Root Working Directory: /content/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "f8270d27-db51-4a01-91ec-3bbc12213e82",
        "scrolled": true,
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24be5a4f-5514-4954-e3f7-7c4ac18b4971"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running in Directory: /content/ComfyUI-Notebook/\n"
          ]
        }
      ],
      "source": [
        "#@title $\\color{orange}{\\textsf{Run This Cell To Setup Jupyter Notebook/Lab to Run ComfyUI-Notebook}}$\n",
        "import os\n",
        "import subprocess\n",
        "\n",
        "try:\n",
        "    from google.colab import drive\n",
        "    HOME = \"/content/\"\n",
        "except:\n",
        "    HOME = \"/workspace/\"\n",
        "override_working_dir = False #@param{type:\"boolean\"}\n",
        "override_dir = \"/content/ComfyUI-Notebook/\" #@param{type:\"string\"}\n",
        "run_full_setup_for_jupyter = False #@param{type:\"boolean\"}\n",
        "install_comfy = True #@param{type:\"boolean\"}\n",
        "install_esrgan = False #@param{type:\"boolean\"}\n",
        "xformers_version = 'xformers==0.0.20' #@param{type:\"string\"}\n",
        "\n",
        "def setup_comfy():\n",
        "    if run_full_setup_for_jupyter:\n",
        "        subprocess.run('curl -fsSL https://deb.nodesource.com/setup_18.x | sudo -E bash -', shell=True)\n",
        "        subprocess.run(['sudo', 'apt-get', 'install', '-y', 'nodejs'])\n",
        "\n",
        "        subprocess.run(['apt-get', 'update'])\n",
        "        subprocess.run(['apt-get', 'install', 'ffmpeg', 'libsm6', 'libxext6', '-y'])\n",
        "        subprocess.run(['pip', 'install', 'pandas'])\n",
        "\n",
        "        subprocess.run(['sudo', 'apt-get', 'update'])\n",
        "        subprocess.run(['sudo', 'apt-get', 'install', 'npm', '-y'])\n",
        "    if install_comfy:\n",
        "        os.system(\"git clone https://github.com/AIManifest/ComfyUI-Notebook.git\")\n",
        "    if install_esrgan:\n",
        "        os.system(\"git clone https://github.com/AIManifest/ESRGAN.git\")\n",
        "\n",
        "    WORKING_DIR = os.path.join(HOME, \"ComfyUI-Notebook/\")\n",
        "    if override_working_dir:\n",
        "        WORKING_DIR = override_dir\n",
        "    os.chdir(WORKING_DIR)\n",
        "    print(f'Running in Directory: {WORKING_DIR}')\n",
        "    subprocess.run(['pip', 'install', '-r', 'requirements.txt'])\n",
        "    subprocess.run(['pip', 'install', 'triton', xformers_version, 'pytorch-lightning'])\n",
        "\n",
        "setup_comfy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25ffff43-a971-414f-b413-664cecd66dd6",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange}{\\textsf{Install Models}}$\n",
        "import os\n",
        "import time\n",
        "import shutil\n",
        "import requests\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "model_dir = \"/content/ComfyUI-Notebook/models/checkpoints/\" #@param{type:\"string\"}\n",
        "vae_dir = \"/content/ComfyUI-Notebook/models/vae/\" #@param{type:\"string\"}\n",
        "lora_dir = \"/content/ComfyUI-Notebook/models/loras/\" #@param{type:\"string\"}\n",
        "\n",
        "# Add boolean parameters for each model\n",
        "download_sd_xl_offset_example_lora_1_0 = True #@param {type:\"boolean\"}\n",
        "download_sd_xl_base_1_0 = True #@param {type:\"boolean\"}\n",
        "download_sd_xl_refiner_1_0 = True #@param {type:\"boolean\"}\n",
        "download_sd_xl_base_1_0_0_9vae = True #@param {type:\"boolean\"}\n",
        "download_sd_xl_refiner_1_0_0_9vae = True #@param {type:\"boolean\"}\n",
        "download_dreamshaperXL10_alpha2XI10 = True #@param {type:\"boolean\"}\n",
        "\n",
        "def download_sdxl():\n",
        "    models_to_download = [\n",
        "        (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\", lora_dir, \"sd_xl_offset_example-lora_1.0.safetensors\", download_sd_xl_offset_example_lora_1_0),\n",
        "        (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors\", model_dir, \"sd_xl_base_1.0.safetensors\", download_sd_xl_base_1_0),\n",
        "        (\"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors\", model_dir, \"sd_xl_refiner_1.0.safetensors\", download_sd_xl_refiner_1_0),\n",
        "        (\"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0_0.9vae.safetensors\", model_dir, \"sd_xl_base_1.0_0.9vae.safetensors\", download_sd_xl_base_1_0_0_9vae),\n",
        "        (\"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0_0.9vae.safetensors\", model_dir, \"sd_xl_refiner_1.0_0.9vae.safetensors\", download_sd_xl_refiner_1_0_0_9vae),\n",
        "        (\"https://civitai.com/api/download/models/126688\", model_dir, \"dreamshaperXL10_alpha2XI10.safetensors\", download_dreamshaperXL10_alpha2XI10)\n",
        "    ]\n",
        "\n",
        "    username = \"AIManifest\"\n",
        "    password = \"winterfellCCJP04\"\n",
        "\n",
        "    for model_URL, folder_path, filename, download in models_to_download:\n",
        "        if not download:\n",
        "            continue\n",
        "\n",
        "        if not os.path.exists(folder_path):\n",
        "            os.makedirs(folder_path, exist_ok=True)\n",
        "\n",
        "        if not os.path.exists(os.path.join(folder_path, filename)):\n",
        "            start_time = time.time()\n",
        "\n",
        "            try:\n",
        "                auth = (username, password) if username and password else None\n",
        "                with requests.get(model_URL, stream=True, auth=auth) as r:\n",
        "\n",
        "                    total_length = int(r.headers.get(\"Content-Length\"))\n",
        "\n",
        "                    with tqdm.wrapattr(r.raw, \"read\", total=total_length, desc=\"..Downloading..\", colour='orange') as raw:\n",
        "\n",
        "                        with open(os.path.join(folder_path, filename), 'wb')as output:\n",
        "                            shutil.copyfileobj(raw, output)\n",
        "\n",
        "                end_time = time.time()\n",
        "                final_time = end_time-start_time\n",
        "                print(f\"\\033[38;2;255;192;203mDone! Model {filename} downloaded in {final_time:.2f} seconds!\")\n",
        "                print(f\"\\033[38;2;255;192;203mFile {filename} downloaded and saved to {folder_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while downloading the model: {e}\")\n",
        "\n",
        "download_sdxl()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<left><font color=\"orange\" size=\"6\"><b>Run ComfyUI-Notebook For Web Browser</b></font></left>"
      ],
      "metadata": {
        "id": "EIOEsLAOKh_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffd118d1-4915-4b9b-b582-c9ddfbd85198",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange}{\\textsf{Run ComfyUI-Notebook For Web Browser}}$\n",
        "working_dir = \"/content/ComfyUI-Notebook\" #@param{type:\"string\"}\n",
        "%cd $working_dir\n",
        "!npm install -g localtunnel\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import socket\n",
        "import urllib.request\n",
        "\n",
        "def iframe_thread(port):\n",
        "  while True:\n",
        "      time.sleep(0.5)\n",
        "      sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
        "      result = sock.connect_ex(('127.0.0.1', port))\n",
        "      if result == 0:\n",
        "        break\n",
        "      sock.close()\n",
        "  print(\"\\nComfyUI-Notebook finished loading, trying to launch localtunnel (if it gets stuck here localtunnel is having issues)\\n\")\n",
        "\n",
        "  print(\"The password/enpoint ip for localtunnel is:\", urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))\n",
        "  p = subprocess.Popen([\"lt\", \"--port\", \"{}\".format(port)], stdout=subprocess.PIPE)\n",
        "  for line in p.stdout:\n",
        "    print(line.decode(), end='')\n",
        "\n",
        "\n",
        "threading.Thread(target=iframe_thread, daemon=True, args=(8188,)).start()\n",
        "\n",
        "!python main.py --dont-print-server --preview-method \"auto\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#<left><font color=\"orange\" size=\"6\"><b>Run ComfyUI-Notebook Notebook System</b></font></left>"
      ],
      "metadata": {
        "id": "4ihuALIcK131"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\color{orange} {\\textsf {RUN SDXL -> Single Prompt!}}$\n"
      ],
      "metadata": {
        "id": "DqGYvxZoHk_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "id": "18addcb8-37ca-4d46-98a1-6ee74a90ff53",
        "tags": [],
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange}{\\textsf{Set CudaMallocAsync}}$\n",
        "import os\n",
        "env_var = \"backend:cudaMallocAsync\"\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = env_var\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "editable": true,
        "id": "d28b9403-ab5e-4ad4-8934-cebf3bb356db",
        "tags": [],
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d9d05f3-842c-4440-80d5-d45d3878b91f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@title $\\color{orange} {\\textsf {RUN SDXL -> Single Prompt!}}$\n",
        "working_dir = \"/content/ComfyUI-Notebook\" #@param{type:\"string\"}\n",
        "%cd $working_dir\n",
        "import torch\n",
        "import random\n",
        "import sdxlrun\n",
        "from types import SimpleNamespace\n",
        "from comfy import model_management\n",
        "from sdxlrun import runsdxl, loadsdxl\n",
        "from pytorch_lightning import seed_everything\n",
        "from refinersdxlrun import runsdxlrefiner, loadsdxlrefiner\n",
        "from iprogress import iprogress\n",
        "\n",
        "def SDXL_ARGS():\n",
        "    prompt = \"\" #@param{type:\"string\"}\n",
        "    negativeprompt = \"\" #@param{type:\"string\"}\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model Options}}$\n",
        "    ckpt_path='/content/ComfyUI/models/checkpoints/dreamshaperXL10_alpha2XI10.safetensors'\n",
        "    ckpt_name='dreamshaperXL10_alpha2XI10.safetensors' #@param{type:\"string\"}[\"sd_xl_base_1.0_0.9vae.safetensors\", \"dreamshaperXL10_alpha2XI10.safetensors\"]\n",
        "    lora_name = \"None\"#@param{type:\"string\"}[\"None\", \"sd_xl_offset_example-lora_1.0.safetensors\", \"greg_rutkowski_xl_2.safetensors\"]\n",
        "    if lora_name == \"None\":\n",
        "        lora_name = None\n",
        "    else:\n",
        "        strength_model = 0.5 #@param{type:\"number\"}\n",
        "        strength_clip = 0.5 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model}}$\n",
        "    steps = 60 #@param{type:\"number\"}\n",
        "    start_step = 0 #@param{type:\"number\"}\n",
        "    last_step = 50 #@param{type:\"number\"}\n",
        "\n",
        "    #refiner model\n",
        "    refiner_steps = steps\n",
        "    refiner_start_step = last_step\n",
        "    refiner_last_step = steps\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Image-Batch Settings}}$\n",
        "    imagewidth = 768 #@param{type:\"number\"}\n",
        "    imageheight = 1200   #@param{type:\"number\"}\n",
        "    batch_size = 1 #@param{type:\"number\"}\n",
        "\n",
        "    cfg = 7 #@param{type:\"number\"}\n",
        "    seed = -1 #@param{type:\"number\"}\n",
        "    if seed == -1:\n",
        "        seed = random.randint(1, 432043209)\n",
        "    seed = seed_everything(seed)\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Settings}}$\n",
        "    sampler_name = \"dpmpp_2m\" #@param{type:\"string\"} [\"euler\", \"euler_ancestral\", \"heun\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"]\n",
        "    scheduler = \"karras\" #@param{type:\"string\"} [\"normal\", \"karras\", \"exponential\", \"simple\", \"ddim_uniform\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Options}}$\n",
        "    s_churn = 0. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmin = 0.1 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmax = float('inf')\n",
        "    s_noise = 1. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "    eta = 1. #@param{type:\"number\"}\n",
        "\n",
        "    order = 4 #@param{type:\"slider\", min:1, max:4, step:1}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{CLIP Options}}$\n",
        "    stop_at_last_layer = -12 #@param{type:\"number\"}\n",
        "    width = 4096 #@param{type:\"number\"}\n",
        "    height = 4096 #@param{type:\"number\"}\n",
        "    crop_w = 0 #@param{type:\"number\"}\n",
        "    crop_h = 0 #@param{type:\"number\"}\n",
        "    target_width = 4096 #@param{type:\"number\"}\n",
        "    target_height = 4096 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Noise Options}}$\n",
        "    denoise = 1.0 #@param{type:\"number\"}\n",
        "    force_full_denoise = False #@param{type:\"boolean\"}\n",
        "    disable_noise = False #@param{type:\"boolean\"}\n",
        "    noisedevice = \"cuda:0\" #@param{type:\"string\"}[\"cuda:0\", \"cpu\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{REFINER OPTIONS}}$\n",
        "    refinerckpt_name='sd_xl_refiner_1.0_0.9vae.safetensors' #@param{type:\"string\"} [\"sd_xl_refiner_1.0_0.9vae.safetensors\", \"sd_xl_refiner_1.0.safetensors\"]\n",
        "    refinerforce_full_denoise = True #@param{type:\"boolean\"}\n",
        "    refinerdisable_noise = True #@param{type:\"boolean\"}\n",
        "    refinerwidth = 4096 #@param{type:\"number\"}\n",
        "    refinerheight = 4096 #@param{type:\"number\"}\n",
        "    ascore = 3.0 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Save Options}}$\n",
        "    output_folder = \"cosmic\" #@param{type:\"string\"}\n",
        "    saveprefix = f'{sampler_name}_{scheduler}'\n",
        "    save_base_image = True #@param{type:\"boolean\"}\n",
        "\n",
        "    vae_decode_method = \"tiled\" #@param{type:\"string\"}[\"normal\", \"tiled\"]\n",
        "\n",
        "    use_preview = True #@param{type:\"boolean\"}\n",
        "\n",
        "    return locals()\n",
        "\n",
        "sdxl_args = SDXL_ARGS()\n",
        "sdxl_args = SimpleNamespace(**sdxl_args)\n",
        "\n",
        "with torch.inference_mode():\n",
        "    try:\n",
        "        out\n",
        "        refined_out\n",
        "    except:\n",
        "        out = loadsdxl(sdxl_args)\n",
        "        refined_out = loadsdxlrefiner(sdxl_args)\n",
        "    model, samples = runsdxl(sdxl_args, out)\n",
        "    model_management.unload_model(model)\n",
        "    model_management.unload_model(out[1].patcher)\n",
        "    sdxlrun.get_device_memory()\n",
        "    refinermodel, refinedsamples = runsdxlrefiner(sdxl_args, samples, model, refined_out)\n",
        "    model_management.unload_model(refinermodel)\n",
        "    model_management.unload_model(refined_out[1].patcher)\n",
        "    sdxlrun.get_device_memory()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\color{orange} {\\textsf {RUN SDXL -> Single Prompt for All Schedulers and Samplers}}$\n"
      ],
      "metadata": {
        "id": "ISjrgi9xHgNo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "cellView": "form",
        "id": "fi9Ox4sYNLn_"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange}{\\textsf{Set CudaMallocAsync}}$\n",
        "import os\n",
        "env_var = \"backend:cudaMallocAsync\"\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = env_var\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "H_IH88GCruYd"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange} {\\textsf {RUN SDXL -> Single Prompt for All Schedulers and Samplers}}$\n",
        "working_dir = \"/content/ComfyUI-Notebook\" #@param{type:\"string\"}\n",
        "%cd $working_dir\n",
        "import torch\n",
        "import random\n",
        "import sdxlrun\n",
        "from types import SimpleNamespace\n",
        "from comfy import model_management\n",
        "from sdxlrun import runsdxl, loadsdxl\n",
        "from pytorch_lightning import seed_everything\n",
        "from refinersdxlrun import runsdxlrefiner, loadsdxlrefiner\n",
        "from iprogress import iprogress\n",
        "\n",
        "def SDXL_ARGS():\n",
        "    prompt = \"\"\n",
        "    negativeprompt = \"\"\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model Options}}$\n",
        "    ckpt_path='/content/ComfyUI/models/checkpoints/dreamshaperXL10_alpha2XI10.safetensors'\n",
        "    ckpt_name='dreamshaperXL10_alpha2XI10.safetensors' #@param{type:\"string\"}[\"sd_xl_base_1.0_0.9vae.safetensors\", \"dreamshaperXL10_alpha2XI10.safetensors\"]\n",
        "    lora_name = \"None\"#@param{type:\"string\"}[\"None\", \"sd_xl_offset_example-lora_1.0.safetensors\", \"greg_rutkowski_xl_2.safetensors\"]\n",
        "    if lora_name == \"None\":\n",
        "        lora_name = None\n",
        "    else:\n",
        "        strength_model = 0.5 #@param{type:\"number\"}\n",
        "        strength_clip = 0.5 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model}}$\n",
        "    steps = 60 #@param{type:\"number\"}\n",
        "    start_step = 0 #@param{type:\"number\"}\n",
        "    last_step = 50 #@param{type:\"number\"}\n",
        "\n",
        "    #refiner model\n",
        "    refiner_steps = steps\n",
        "    refiner_start_step = last_step\n",
        "    refiner_last_step = steps\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Image-Batch Settings}}$\n",
        "    imagewidth = 768 #@param{type:\"number\"}\n",
        "    imageheight = 1200   #@param{type:\"number\"}\n",
        "    batch_size = 1 #@param{type:\"number\"}\n",
        "\n",
        "    cfg = 7 #@param{type:\"number\"}\n",
        "    seed = -1 #@param{type:\"number\"}\n",
        "    if seed == -1:\n",
        "        seed = random.randint(1, 432043209)\n",
        "    seed = seed_everything(seed)\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Settings}}$\n",
        "    sampler_name = \"dpmpp_2m\" #@param{type:\"string\"} [\"euler\", \"euler_ancestral\", \"heun\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"]\n",
        "    scheduler = \"karras\" #@param{type:\"string\"} [\"normal\", \"karras\", \"exponential\", \"simple\", \"ddim_uniform\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Options}}$\n",
        "    s_churn = 0. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmin = 0.1 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmax = float('inf')\n",
        "    s_noise = 1. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "    eta = 1. #@param{type:\"number\"}\n",
        "\n",
        "    order = 4 #@param{type:\"slider\", min:1, max:4, step:1}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{CLIP Options}}$\n",
        "    stop_at_last_layer = -12 #@param{type:\"number\"}\n",
        "    width = 4096 #@param{type:\"number\"}\n",
        "    height = 4096 #@param{type:\"number\"}\n",
        "    crop_w = 0 #@param{type:\"number\"}\n",
        "    crop_h = 0 #@param{type:\"number\"}\n",
        "    target_width = 4096 #@param{type:\"number\"}\n",
        "    target_height = 4096 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Noise Options}}$\n",
        "    denoise = 1.0 #@param{type:\"number\"}\n",
        "    force_full_denoise = False #@param{type:\"boolean\"}\n",
        "    disable_noise = False #@param{type:\"boolean\"}\n",
        "    noisedevice = \"cuda:0\" #@param{type:\"string\"}[\"cuda:0\", \"cpu\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{REFINER OPTIONS}}$\n",
        "    refinerckpt_name='sd_xl_refiner_1.0_0.9vae.safetensors' #@param{type:\"string\"} [\"sd_xl_refiner_1.0_0.9vae.safetensors\", \"sd_xl_refiner_1.0.safetensors\"]\n",
        "    refinerforce_full_denoise = True #@param{type:\"boolean\"}\n",
        "    refinerdisable_noise = True #@param{type:\"boolean\"}\n",
        "    refinerwidth = 4096 #@param{type:\"number\"}\n",
        "    refinerheight = 4096 #@param{type:\"number\"}\n",
        "    ascore = 3.0 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Save Options}}$\n",
        "    output_folder = \"cosmic\" #@param{type:\"string\"}\n",
        "    saveprefix = f'{sampler_name}_{scheduler}'\n",
        "    save_base_image = True #@param{type:\"boolean\"}\n",
        "\n",
        "    vae_decode_method = \"tiled\" #@param{type:\"string\"}[\"normal\", \"tiled\"]\n",
        "\n",
        "    use_preview = True #@param{type:\"boolean\"}\n",
        "\n",
        "    return locals()\n",
        "\n",
        "# [\"euler\", \"euler_ancestral\", \"heun\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\",]\n",
        "sampler_names = [\"euler\", \"euler_ancestral\", \"heun\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"]\n",
        "schedulers = [\"normal\", \"karras\", \"exponential\", \"simple\", \"ddim_uniform\"]\n",
        "randomize_seed = False #@param{type:\"boolean\"}\n",
        "\n",
        "for sampler_name in iprogress(sampler_names, colour=\"synthlite\"):\n",
        "    for scheduler in iprogress(schedulers, colour=\"cotton_candy\"):\n",
        "        if randomize_seed:\n",
        "            seed = seed_everything(random.randint(2 ** 64))\n",
        "        sdxl_args = SDXL_ARGS()\n",
        "        sdxl_args = SimpleNamespace(**sdxl_args)\n",
        "        sdxl_args.sampler_name = sampler_name\n",
        "        sdxl_args.scheduler = scheduler\n",
        "        sdxl_args.saveprefix = f'{sampler_name}_{scheduler}'\n",
        "        with torch.inference_mode():\n",
        "            try:\n",
        "                out\n",
        "                refined_out\n",
        "            except:\n",
        "                out = loadsdxl(sdxl_args)\n",
        "                refined_out = loadsdxlrefiner(sdxl_args)\n",
        "\n",
        "            model, samples = runsdxl(sdxl_args, out)\n",
        "            model_management.unload_model(model)\n",
        "            model_management.unload_model(out[1].patcher)\n",
        "            sdxlrun.get_device_memory()\n",
        "            refinermodel, refinedsamples = runsdxlrefiner(sdxl_args, samples, model, refined_out)\n",
        "            model_management.unload_model(refinermodel)\n",
        "            model_management.unload_model(refined_out[1].patcher)\n",
        "            sdxlrun.get_device_memory()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##$\\color{orange} {\\textsf{Run SDXL -> Multi-Prompt}}$\n"
      ],
      "metadata": {
        "id": "0HHS0z7bHa2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "editable": true,
        "tags": [],
        "cellView": "form",
        "id": "6zo0-odFNMmc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b6a011f-52e2-4970-ae78-14bc6c1f3842"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'backend:cudaMallocAsync'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "#@title $\\color{orange}{\\textsf{Set CudaMallocAsync}}$\n",
        "import os\n",
        "env_var = \"backend:cudaMallocAsync\"\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = env_var\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = {\n",
        "    1: \"(dark magic), (grim), ten horns, ten diadems, (intricate details), (hyperdetailed), 8k hdr, high detailed, lot of details, high quality, soft cinematic light, dramatic atmosphere, atmospheric perspective\",\n",
        "    # 2: \"an extremely detailed portrait of the last supper with jesus and the disciples by leonardo da vinci in rick and morti art style, picture perfect\"\n",
        "}\n",
        "\n",
        "negative_prompts = {\n",
        "    1: \"blur, dof, bokeh\",\n",
        "    # 2: \"noisy, not sharp, unclear, deformed, disproportionate, hybrid,female, woman, close up, zoomed, zoomed image, low res, low quality, low detail, low dynamic, poorly composed, poorly detailed, poorly proportioned, overblown image\",\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "NEyM4IQAgZOC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xOlOmWGCpKKI",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title $\\color{orange} {\\textsf{Run SDXL -> Multi-Prompt}}$\n",
        "working_dir = \"/content/ComfyUI-Notebook\" #@param{type:\"string\"}\n",
        "%cd $working_dir\n",
        "import torch\n",
        "import random\n",
        "import sdxlrun\n",
        "from types import SimpleNamespace\n",
        "from comfy import model_management\n",
        "from sdxlrun import runsdxl, loadsdxl\n",
        "from pytorch_lightning import seed_everything\n",
        "from refinersdxlrun import runsdxlrefiner, loadsdxlrefiner\n",
        "from iprogress import iprogress\n",
        "\n",
        "def SDXL_ARGS():\n",
        "    prompt = \"\"\n",
        "    negativeprompt = \"\"\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model Options}}$\n",
        "    ckpt_path='/content/ComfyUI/models/checkpoints/dreamshaperXL10_alpha2XI10.safetensors'\n",
        "    ckpt_name='dreamshaperXL10_alpha2XI10.safetensors' #@param{type:\"string\"}[\"sd_xl_base_1.0_0.9vae.safetensors\", \"dreamshaperXL10_alpha2XI10.safetensors\"]\n",
        "    lora_name = \"None\"#@param{type:\"string\"}[\"None\", \"sd_xl_offset_example-lora_1.0.safetensors\", \"greg_rutkowski_xl_2.safetensors\"]\n",
        "    if lora_name == \"None\":\n",
        "        lora_name = None\n",
        "    else:\n",
        "        strength_model = 0.5 #@param{type:\"number\"}\n",
        "        strength_clip = 0.5 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Base Model}}$\n",
        "    steps = 60 #@param{type:\"number\"}\n",
        "    start_step = 0 #@param{type:\"number\"}\n",
        "    last_step = 50 #@param{type:\"number\"}\n",
        "\n",
        "    #refiner model\n",
        "    refiner_steps = steps\n",
        "    refiner_start_step = last_step\n",
        "    refiner_last_step = steps\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Image-Batch Settings}}$\n",
        "    imagewidth = 768 #@param{type:\"number\"}\n",
        "    imageheight = 1200   #@param{type:\"number\"}\n",
        "    batch_size = 1 #@param{type:\"number\"}\n",
        "\n",
        "    cfg = 7 #@param{type:\"number\"}\n",
        "    seed = -1 #@param{type:\"number\"}\n",
        "    if seed == -1:\n",
        "        seed = random.randint(1, 432043209)\n",
        "    seed = seed_everything(seed)\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Settings}}$\n",
        "    sampler_name = \"dpmpp_2m\" #@param{type:\"string\"} [\"euler\", \"euler_ancestral\", \"heun\", \"dpm_2\", \"dpm_2_ancestral\", \"lms\", \"dpm_fast\", \"dpm_adaptive\", \"dpmpp_2s_ancestral\", \"dpmpp_sde\", \"dpmpp_sde_gpu\", \"dpmpp_2m\", \"dpmpp_2m_sde\", \"dpmpp_2m_sde_gpu\", \"ddim\", \"uni_pc\", \"uni_pc_bh2\"]\n",
        "    scheduler = \"karras\" #@param{type:\"string\"} [\"normal\", \"karras\", \"exponential\", \"simple\", \"ddim_uniform\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Sampler Options}}$\n",
        "    s_churn = 0. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmin = 0.1 # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "    s_tmax = float('inf')\n",
        "    s_noise = 1. # @param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "    eta = 1. #@param{type:\"number\"}\n",
        "\n",
        "    order = 4 #@param{type:\"slider\", min:1, max:4, step:1}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{CLIP Options}}$\n",
        "    stop_at_last_layer = -12 #@param{type:\"number\"}\n",
        "    width = 4096 #@param{type:\"number\"}\n",
        "    height = 4096 #@param{type:\"number\"}\n",
        "    crop_w = 0 #@param{type:\"number\"}\n",
        "    crop_h = 0 #@param{type:\"number\"}\n",
        "    target_width = 4096 #@param{type:\"number\"}\n",
        "    target_height = 4096 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Noise Options}}$\n",
        "    denoise = 1.0 #@param{type:\"number\"}\n",
        "    force_full_denoise = False #@param{type:\"boolean\"}\n",
        "    disable_noise = False #@param{type:\"boolean\"}\n",
        "    noisedevice = \"cuda:0\" #@param{type:\"string\"}[\"cuda:0\", \"cpu\"]\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{REFINER OPTIONS}}$\n",
        "    refinerckpt_name='sd_xl_refiner_1.0_0.9vae.safetensors' #@param{type:\"string\"} [\"sd_xl_refiner_1.0_0.9vae.safetensors\", \"sd_xl_refiner_1.0.safetensors\"]\n",
        "    refinerforce_full_denoise = True #@param{type:\"boolean\"}\n",
        "    refinerdisable_noise = True #@param{type:\"boolean\"}\n",
        "    refinerwidth = 4096 #@param{type:\"number\"}\n",
        "    refinerheight = 4096 #@param{type:\"number\"}\n",
        "    ascore = 3.0 #@param{type:\"number\"}\n",
        "\n",
        "    #@markdown $\\color{orange}{\\textsf{Save Options}}$\n",
        "    output_folder = \"cosmic\" #@param{type:\"string\"}\n",
        "    saveprefix = f'{sampler_name}_{scheduler}'\n",
        "    save_base_image = True #@param{type:\"boolean\"}\n",
        "\n",
        "    vae_decode_method = \"tiled\" #@param{type:\"string\"}[\"normal\", \"tiled\"]\n",
        "\n",
        "    use_preview = True #@param{type:\"boolean\"}\n",
        "\n",
        "    return locals()\n",
        "\n",
        "sdxl_args = SDXL_ARGS()\n",
        "sdxl_args = SimpleNamespace(**sdxl_args)\n",
        "randomize_seed = False\n",
        "\n",
        "key=1\n",
        "for prompt_id, prompt in prompts.items():\n",
        "    sdxl_args.prompt = prompt\n",
        "    sdxl_args.negativeprompt = negative_prompts[key]\n",
        "    print(f'Running with Prompt: {sdxl_args.prompt}')\n",
        "    print(f'Running with Negative Prompt: {sdxl_args.negativeprompt}')\n",
        "    if randomize_seed:\n",
        "        seed = seed_everything(random.randint(2 ** 64))\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        try:\n",
        "            out\n",
        "            refined_out\n",
        "        except:\n",
        "            out = loadsdxl(sdxl_args)\n",
        "            refined_out = loadsdxlrefiner(sdxl_args)\n",
        "\n",
        "        model, samples = runsdxl(sdxl_args, out)\n",
        "        model_management.unload_model(model)\n",
        "        model_management.unload_model(out[1].patcher)\n",
        "        sdxlrun.get_device_memory()\n",
        "        refinermodel, refinedsamples = runsdxlrefiner(sdxl_args, samples, model, refined_out)\n",
        "        model_management.unload_model(refinermodel)\n",
        "        model_management.unload_model(refined_out[1].patcher)\n",
        "        sdxlrun.get_device_memory()\n",
        "        key+=1\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "collapsed_sections": [
        "0SLoofuGZFd-",
        "EIOEsLAOKh_m",
        "4ihuALIcK131",
        "DqGYvxZoHk_c",
        "ISjrgi9xHgNo",
        "0HHS0z7bHa2Q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}